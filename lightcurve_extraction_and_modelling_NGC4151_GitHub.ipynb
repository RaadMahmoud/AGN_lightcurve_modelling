{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Section 1) Data extraction."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we extract light curves from our three energy bands, interpolate and rebin them, and derive their cross correlation functions.\n",
    "\n",
    "No modelling is performed in this section."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pylab import *\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "font = {'family' : 'normal',\n",
    "        'style'  : 'italic',\n",
    "        'size'   : 15} # or 10 for triplot\n",
    "matplotlib.rc('font', **font)\n",
    "%matplotlib inline\n",
    "import scipy.optimize\n",
    "import csv\n",
    "pi = np.pi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Set up binning scales in wavelength, energy and time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt_sim = 0.05\n",
    "dt_dat= 0.05\n",
    "dt_rebn = 0.5\n",
    "\n",
    "taus = np.arange(-20, 20, dt_rebn)\n",
    "\n",
    "wav_range = np.array((5468, 4392, 3465, 2600, 2246, 1928, 25.3, 4.4))\n",
    "dwav_range = np.array((5800-5050, 4900-3900,3900-3050,2950-2250,2500-2000,2250-1650, 41.3-15.5, 15.5-1.2))\n",
    "\n",
    "E_range = 12.398/wav_range\n",
    "dE_range = np.array((12.398/5050 - 12.398/5800,\\\n",
    "            12.398/3900 - 12.398/4900,\\\n",
    "            12.398/3050 - 12.398/3900,\n",
    "            12.398/2250 - 12.398/2950,\n",
    "            12.398/2000 - 12.398/2500,\n",
    "            12.398/1650 - 12.398/2250,\n",
    "            12.398/15.5 - 12.398/41.3,\n",
    "            12.398/1.20 - 12.398/15.5))\n",
    "\n",
    "dE_range = dE_range/2.\n",
    "dwav_range = dwav_range/2.\n",
    "\n",
    "E_UVW1 = E_range[3]\n",
    "dE_UVW1 = dE_range[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract the raw light curves, and set up time bins in each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "objectname = np.array(())\n",
    "\n",
    "cadence = np.array(())\n",
    "\n",
    "MJD_U = np.array(())\n",
    "MJD_B = np.array(())\n",
    "MJD_HX = np.array(())\n",
    "MJD_SX = np.array(())\n",
    "MJD_UVW2 = np.array(())\n",
    "MJD_V = np.array(())\n",
    "MJD_UVM2 = np.array(())\n",
    "MJD_UVW1 = np.array(())\n",
    "\n",
    "duration_U = np.array(())\n",
    "duration_B = np.array(())\n",
    "duration_HX = np.array(())\n",
    "duration_SX = np.array(())\n",
    "duration_UVW2 = np.array(())\n",
    "duration_V = np.array(())\n",
    "duration_UVM2 = np.array(())\n",
    "duration_UVW1 = np.array(())\n",
    "\n",
    "flux_U = np.array(())\n",
    "flux_B = np.array(())\n",
    "flux_HX = np.array(())\n",
    "flux_SX = np.array(())\n",
    "flux_UVW2 = np.array(())\n",
    "flux_V = np.array(())\n",
    "flux_UVM2 = np.array(())\n",
    "flux_UVW1 = np.array(())\n",
    "\n",
    "flux_err_U = np.array(())\n",
    "flux_err_B = np.array(())\n",
    "flux_err_HX = np.array(())\n",
    "flux_err_SX = np.array(())\n",
    "flux_err_UVW2 = np.array(())\n",
    "flux_err_V = np.array(())\n",
    "flux_err_UVM2 = np.array(())\n",
    "flux_err_UVW1 = np.array(())\n",
    "\n",
    "with open('raw_lightcurves/NGC4151/lcdata.csv', 'rb') as csvfile:\n",
    "     data_file = csv.reader(csvfile, delimiter=',', quotechar='|')\n",
    "     for row in data_file:\n",
    "         if row[0] == '\"NGC4151\"':\n",
    "             if row[1] == '\"U\"':\n",
    "                 MJD_U = np.append(MJD_U, row[3])\n",
    "                 duration_U = np.append(duration_U, row[4])\n",
    "                 flux_U = np.append(flux_U, row[5])\n",
    "                 flux_err_U = np.append(flux_err_U, row[6])\n",
    "             elif row[1] == '\"B\"':\n",
    "                 MJD_B = np.append(MJD_B, row[3])\n",
    "                 duration_B = np.append(duration_B, row[4])\n",
    "                 flux_B = np.append(flux_B, row[5])\n",
    "                 flux_err_B = np.append(flux_err_B, row[6])\n",
    "             elif row[1] == '\"HX\"':\n",
    "                 MJD_HX = np.append(MJD_HX, row[3])\n",
    "                 duration_HX = np.append(duration_HX, row[4])\n",
    "                 flux_HX = np.append(flux_HX, row[5])\n",
    "                 flux_err_HX = np.append(flux_err_HX, row[6])\n",
    "             elif row[1] == '\"SX\"':\n",
    "                 MJD_SX = np.append(MJD_SX, row[3])\n",
    "                 duration_SX = np.append(duration_SX, row[4])\n",
    "                 flux_SX = np.append(flux_SX, row[5])\n",
    "                 flux_err_SX = np.append(flux_err_SX, row[6])\n",
    "             elif row[1] == '\"UVW2\"':\n",
    "                 MJD_UVW2 = np.append(MJD_UVW2, row[3])\n",
    "                 duration_UVW2 = np.append(duration_UVW2, row[4])\n",
    "                 flux_UVW2 = np.append(flux_UVW2, row[5])\n",
    "                 flux_err_UVW2 = np.append(flux_err_UVW2, row[6])\n",
    "             elif row[1] == '\"V\"':\n",
    "                 MJD_V = np.append(MJD_V, row[3])\n",
    "                 duration_V = np.append(duration_V, row[4])\n",
    "                 flux_V = np.append(flux_V, row[5])\n",
    "                 flux_err_V = np.append(flux_err_V, row[6])\n",
    "             elif row[1] == '\"UVM2\"':\n",
    "                 MJD_UVM2 = np.append(MJD_UVM2, row[3])\n",
    "                 duration_UVM2 = np.append(duration_UVM2, row[4])\n",
    "                 flux_UVM2 = np.append(flux_UVM2, row[5])\n",
    "                 flux_err_UVM2 = np.append(flux_err_UVM2, row[6])\n",
    "             elif row[1] == '\"UVW1\"':\n",
    "                 MJD_UVW1 = np.append(MJD_UVW1, row[3])\n",
    "                 duration_UVW1 = np.append(duration_UVW1, row[4])\n",
    "                 flux_UVW1 = np.append(flux_UVW1, row[5])\n",
    "                 flux_err_UVW1 = np.append(flux_err_UVW1, row[6])\n",
    "                \n",
    "bat_dat = np.genfromtxt('raw_lightcurves/NGC4151/bat.qdp', skip_header=1)\n",
    "MJD_BAT = bat_dat[:,0]\n",
    "flux_BAT = bat_dat[:,1]\n",
    "flux_err_BAT = bat_dat[:,2]\n",
    "\n",
    "MJD_U = MJD_U.astype('float')\n",
    "duration_U = duration_U.astype('float')\n",
    "flux_U = flux_U.astype('float')\n",
    "flux_err_U = flux_err_U.astype('float')\n",
    "dt_U = MJD_U[1:] - MJD_U[:-1]\n",
    "\n",
    "MJD_B = MJD_B.astype('float')\n",
    "duration_B = duration_B.astype('float')\n",
    "flux_B = flux_B.astype('float')\n",
    "flux_err_B = flux_err_B.astype('float')\n",
    "dt_B = MJD_B[1:] - MJD_B[:-1]\n",
    "\n",
    "MJD_HX = MJD_HX.astype('float')\n",
    "duration_HX = duration_HX.astype('float')\n",
    "flux_HX = flux_HX.astype('float')\n",
    "flux_err_HX = flux_err_HX.astype('float')\n",
    "dt_HX = MJD_HX[1:] - MJD_HX[:-1]\n",
    "\n",
    "MJD_SX = MJD_SX.astype('float')\n",
    "duration_SX = duration_SX.astype('float')\n",
    "flux_SX = flux_SX.astype('float')\n",
    "flux_err_SX = flux_err_SX.astype('float')\n",
    "dt_SX = MJD_SX[1:] - MJD_SX[:-1]\n",
    "\n",
    "MJD_UVW2 = MJD_UVW2.astype('float')\n",
    "duration_UVW2 = duration_UVW2.astype('float')\n",
    "flux_UVW2 = flux_UVW2.astype('float')\n",
    "flux_err_UVW2 = flux_err_UVW2.astype('float')\n",
    "dt_UVW2 = MJD_UVW2[1:] - MJD_UVW2[:-1]\n",
    "\n",
    "MJD_V = MJD_V.astype('float')\n",
    "duration_V = duration_V.astype('float')\n",
    "flux_V = flux_V.astype('float')\n",
    "flux_err_V = flux_err_V.astype('float')\n",
    "dt_V = MJD_V[1:] - MJD_V[:-1]\n",
    "\n",
    "MJD_UVM2 = MJD_UVM2.astype('float')\n",
    "duration_UVM2 = duration_UVM2.astype('float')\n",
    "flux_UVM2 = flux_UVM2.astype('float')\n",
    "flux_err_UVM2 = flux_err_UVM2.astype('float')\n",
    "dt_UVM2 = MJD_UVM2[1:] - MJD_UVM2[:-1]\n",
    "\n",
    "MJD_UVW1 = MJD_UVW1.astype('float')\n",
    "duration_UVW1 = duration_UVW1.astype('float')\n",
    "flux_UVW1 = flux_UVW1.astype('float')\n",
    "flux_err_UVW1 = flux_err_UVW1.astype('float')\n",
    "dt_UVW1 = MJD_UVW1[1:] - MJD_UVW1[:-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we interpolate the lightcurves as they were irregularly binned."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comparison_times = np.arange(MJD_SX[0], MJD_SX[-1], dt_dat)\n",
    "flux_BAT_int = np.interp(comparison_times, MJD_BAT, flux_BAT)\n",
    "flux_U_int = np.interp(comparison_times, MJD_U, flux_U)\n",
    "flux_V_int = np.interp(comparison_times, MJD_V, flux_V)\n",
    "flux_B_int = np.interp(comparison_times, MJD_B, flux_B)\n",
    "flux_HX_int = np.interp(comparison_times, MJD_HX, flux_HX)\n",
    "flux_UVW1_int = np.interp(comparison_times, MJD_UVW1, flux_UVW1)\n",
    "flux_UVW2_int = np.interp(comparison_times, MJD_UVW2, flux_UVW2)\n",
    "flux_UVM2_int = np.interp(comparison_times, MJD_UVM2, flux_UVM2)\n",
    "flux_SX_int = np.interp(comparison_times, MJD_SX, flux_SX)\n",
    "\n",
    "flux_err_BAT_int = np.interp(comparison_times, MJD_BAT, flux_err_BAT)\n",
    "flux_err_U_int = np.interp(comparison_times, MJD_U, flux_err_U)\n",
    "flux_err_V_int = np.interp(comparison_times, MJD_V, flux_err_V)\n",
    "flux_err_B_int = np.interp(comparison_times, MJD_B, flux_err_B)\n",
    "flux_err_HX_int = np.interp(comparison_times, MJD_HX, flux_err_HX)\n",
    "flux_err_UVW1_int = np.interp(comparison_times, MJD_UVW1, flux_err_UVW1)\n",
    "flux_err_UVW2_int = np.interp(comparison_times, MJD_UVW2, flux_err_UVW2)\n",
    "flux_err_UVM2_int = np.interp(comparison_times, MJD_UVM2, flux_err_UVM2)\n",
    "flux_err_SX_int = np.interp(comparison_times, MJD_SX, flux_err_SX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can rebin the lightcurves to obtain a more reliable signal/noise. These are the lightcurves we will model later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = np.arange(MJD_SX[0], MJD_SX[-1], dt_rebn)\n",
    "digitized = np.digitize(comparison_times[3:-3], bins)\n",
    "comparison_times_rebn = np.asarray([comparison_times[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_BAT_rebn = np.asarray([flux_BAT_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_U_rebn = np.asarray([flux_U_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_V_rebn = np.asarray([flux_V_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_B_rebn = np.asarray([flux_B_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_HX_rebn = np.asarray([flux_HX_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_SX_rebn = np.asarray([flux_SX_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_UVW1_rebn = np.asarray([flux_UVW1_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_UVW2_rebn = np.asarray([flux_UVW2_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_UVM2_rebn = np.asarray([flux_UVM2_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "\n",
    "flux_err_BAT_rebn = np.asarray([flux_err_BAT_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_err_U_rebn = np.asarray([flux_err_U_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_err_B_rebn = np.asarray([flux_err_B_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_err_V_rebn = np.asarray([flux_err_V_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_err_HX_rebn = np.asarray([flux_err_HX_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_err_SX_rebn = np.asarray([flux_err_SX_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_err_UVW1_rebn = np.asarray([flux_err_UVW1_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_err_UVW2_rebn = np.asarray([flux_err_UVW2_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])\n",
    "flux_err_UVM2_rebn = np.asarray([flux_err_UVM2_int[3:-3][digitized == i].mean() for i in range(1, len(bins))])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the rebinned light curves and have a look at them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, (ax1, ax2, ax3, ax4, ax5, ax6, ax7, ax8,ax9) = plt.subplots(9, sharex = True, figsize = (15, 30))\n",
    "ax1.errorbar(MJD_V, flux_V, flux_err_V, xerr = duration_V/86400., label = 'V', c='g', ls = 'none', fmt = 'x')\n",
    "ax1.set_ylabel('V')\n",
    "ax2.errorbar(MJD_B, flux_B, flux_err_B, xerr = duration_B/86400., label = 'B', c='r', ls = 'none', fmt = 'x')\n",
    "ax2.set_ylabel('B')\n",
    "ax3.errorbar(MJD_U, flux_U, flux_err_U, xerr = duration_U/86400., label = 'U', c='b', ls = 'none', fmt = 'x')\n",
    "ax3.set_ylabel('U')\n",
    "ax4.errorbar(MJD_UVW1, flux_UVW1, flux_err_UVW1, xerr = duration_UVW1/86400., label = 'UVW1', c='m', ls = 'none', fmt = 'x')\n",
    "ax4.set_ylabel('UVW1')\n",
    "ax5.errorbar(MJD_UVM2, flux_UVM2, flux_err_UVM2, xerr = duration_UVM2/86400., label = 'UVM2', c='pink', ls = 'none', fmt = 'x')\n",
    "ax5.set_ylabel('UVM2')\n",
    "ax6.errorbar(MJD_UVW2, flux_UVW2, flux_err_UVW2, xerr = duration_UVW2/86400., label = 'UVW2', c='cyan', ls = 'none', fmt = 'x')\n",
    "ax6.set_ylabel('UVW2')\n",
    "ax7.errorbar(MJD_SX, flux_SX, flux_err_SX, xerr = duration_SX/86400., label = 'SX', c='y', ls = 'none', fmt = 'x')\n",
    "ax7.set_ylabel('SX')\n",
    "ax8.errorbar(MJD_HX, flux_HX, flux_err_HX, xerr = duration_HX/86400., label = 'HX', c='k', ls = 'none', fmt = 'x')\n",
    "ax8.set_ylabel('HX')\n",
    "ax9.errorbar(MJD_BAT, flux_BAT, flux_err_BAT, label = 'BAT', c='purple', ls = 'none', fmt = 'x')\n",
    "ax9.set_ylabel('BAT')\n",
    "\n",
    "f, (ax4, ax9) = plt.subplots(2, sharex = True)\n",
    "ax9.errorbar(MJD_UVW1, flux_UVW1, flux_err_UVW1, xerr = duration_UVW1/86400., label = 'UVW1', c='green', ls = 'none', fmt = 'x')\n",
    "ax9.set_ylabel('UVW1')\n",
    "ax4.errorbar(MJD_BAT, flux_BAT, flux_err_BAT, label = 'BAT', c='cyan', ls = 'none', fmt = 'x')\n",
    "ax4.set_ylabel('BAT')\n",
    "ax9.set_xlabel('MJD')\n",
    "ax4.tick_params(axis = 'both', bottom='on', top='on', left='on', right='on', direction= 'in')\n",
    "ax9.tick_params(axis = 'both', bottom='on', top='on', left='on', right='on', direction= 'in')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will produce cross-correlation functions (CCFs) between our UVM2 band and the other two. To do this we will define the CCF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CCF(s, h, dt, s_err = 0, h_err=0, s_int_err = 0, h_int_err = 0):  \n",
    "    \n",
    "    if type(s_err)==int :\n",
    "        s_err = np.zeros(len(s))\n",
    "    if type(h_err)==int:\n",
    "        h_err = np.zeros(len(h))\n",
    "    \n",
    "    lens = len(s)\n",
    "\n",
    "    corrs = np.zeros(len(taus))\n",
    "    \n",
    "    for j in range(len(taus)):\n",
    "        tau = taus[j]\n",
    "        di = int(tau/dt)\n",
    "        if abs(di) < lens:\n",
    "            if di > 0:\n",
    "                '''Imagine s staying fixed and h 'rolling' forward by di beneath it.'''\n",
    "                s_up = s[:-di]\n",
    "                s_err_up = s_err[:-di]\n",
    "                h_up = h[di:]\n",
    "                h_err_up = h_err[di:]\n",
    "            elif di == 0:\n",
    "                s_up = s\n",
    "                s_err_up = s_err\n",
    "                h_up = h\n",
    "                h_err_up = h_err\n",
    "            else:\n",
    "                s_up = s[abs(di):]\n",
    "                s_err_up = s_err[abs(di):]\n",
    "                h_up = h[:-abs(di)]\n",
    "                h_err_up = h_err[:-abs(di)]     \n",
    "            save = np.average(s_up)\n",
    "            have = np.average(h_up)\n",
    "            sig_s = np.var(s_up)\n",
    "            sig_h = np.var(h_up)\n",
    "            sig_s_err = np.var(s_err_up)\n",
    "            sig_h_err = np.var(h_err_up)\n",
    "            lens_up = len(s_up)\n",
    "            \n",
    "            corrs[j] = np.sum((s_up - save) * (h_up - have)) / lens_up\n",
    "            corrs[j] = corrs[j] / ((sig_s * (1 - s_int_err) - sig_s_err) * (sig_h * (1-h_int_err) - sig_h_err))**0.5\n",
    "        \n",
    "    return corrs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should also correct for interpolation error as in Gardner & Done 2017. This requires that we define a gaussian function and fit our raw CCF using two gaussian functions; the narrow central gaussian will be spurious, and so we can quantify the interpolation error in terms of the narrow gaussian parameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gaussian(x, amp_A, sig2_A, amp_B, sig2_B, K):\n",
    "    return amp_A / np.sqrt(2*pi*sig2_A) * np.exp( - (x)**2 / (2*sig2_A)) + amp_B / np.sqrt(2*pi*sig2_B) * np.exp( - (x)**2 / (2*sig2_B)) + K\n",
    "\n",
    "def CCF_corrected(s, h, dt, s_err, h_err, mode = 'corr'):\n",
    "    if mode == 'corr':\n",
    "        ACF_s = CCF(s, s, dt_rebn, s_err, s_err)\n",
    "        params_s = scipy.optimize.curve_fit(gaussian,taus,ACF_s, maxfev = 50000)[0]\n",
    "        \n",
    "        ACF_h = CCF(h, h, dt_rebn, h_err, h_err)\n",
    "        params_h = scipy.optimize.curve_fit(gaussian,taus,ACF_h, maxfev = 50000)[0]\n",
    "        \n",
    "        sig2_e_s_rat = min(params_s[1], params_s[3]) / max(params_s[1], params_s[3])\n",
    "        sig2_e_h_rat = min(params_h[1], params_h[3]) / max(params_h[1], params_h[3])\n",
    "    \n",
    "        CCF_corr = CCF(s, h, dt, s_err, h_err, sig2_e_s_rat, sig2_e_h_rat)\n",
    "    if mode == 'nocorr':\n",
    "        CCF_corr = CCF(s, h, dt, s_err, h_err)        \n",
    "\n",
    "    return CCF_corr[::-1]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can plot the corrected CCFs of our data and compare them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CCF_SX = CCF_corrected(flux_UVW1_rebn, flux_SX_rebn, dt_rebn, flux_err_UVW1_rebn, flux_err_SX_rebn)\n",
    "CCF_HX = CCF_corrected(flux_UVW1_rebn, flux_HX_rebn, dt_rebn, flux_err_UVW1_rebn, flux_err_HX_rebn)\n",
    "CCF_UVW2 = CCF_corrected(flux_UVW1_rebn, flux_UVW2_rebn, dt_rebn, flux_err_UVW1_rebn, flux_err_UVW2_rebn)\n",
    "CCF_UVM2 = CCF_corrected(flux_UVW1_rebn, flux_UVM2_rebn, dt_rebn, flux_err_UVW1_rebn, flux_err_UVM2_rebn)\n",
    "CCF_V = CCF_corrected(flux_UVW1_rebn, flux_V_rebn, dt_rebn, flux_err_UVW1_rebn, flux_err_V_rebn)\n",
    "CCF_B = CCF_corrected(flux_UVW1_rebn, flux_B_rebn, dt_rebn, flux_err_UVW1_rebn, flux_err_B_rebn)\n",
    "CCF_U = CCF_corrected(flux_UVW1_rebn, flux_U_rebn, dt_rebn, flux_err_UVW1_rebn, flux_err_U_rebn)\n",
    "CCF_BAT = CCF_corrected(flux_UVW1_rebn, flux_BAT_rebn, dt_rebn, flux_err_UVW1_rebn, flux_err_BAT_rebn)\n",
    "\n",
    "f, ax = plt.subplots(figsize=  (15,10))\n",
    "ax.plot(taus, CCF_BAT, c = 'k', alpha = 1/7.)\n",
    "ax.plot(taus, CCF_HX, c = 'k', alpha = 2/7.)\n",
    "ax.plot(taus, CCF_SX, c = 'k', alpha = 3/7.)\n",
    "ax.plot(taus, CCF_UVM2, c = 'k', alpha = 4/7.)\n",
    "ax.plot(taus, CCF_U, c = 'k', alpha = 5/7.)\n",
    "ax.plot(taus, CCF_B, c = 'k', alpha = 6/7.)\n",
    "ax.plot(taus, CCF_V, c = 'k' , alpha = 7/7.)\n",
    "ax.set_title('CCF wrt UVW1. Darker lines are longer wavelength. BAT is palest.')\n",
    "ax.set_xlabel('tau (days)')\n",
    "ax.set_ylabel('normalised CCF')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import scipy\n",
    "import xspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Users should ensure that they either have a version of XSPEC sufficiently new that it contains the model agnsed\n",
    "or that they have agnsed installed as a local model. In the latter case, uncomment and fill in the following piece of code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "xspec.AllModels.initpackage(\"agnmodel\", \"lmodel_agnsed.dat\", \"path/to/your/agnsed_local_model\")\n",
    "xspec.AllModels.lmod(\"agnmodel\", \"path/to/your/agnsed_local_model\")\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''For Raad's use only; please ignore if I've left this in.'''\n",
    "\n",
    "xspec.AllModels.initpackage(\"agnmodel\", \"lmodel_agnsed.dat\", \"/home/raad/PhD/Data/Work_Dir/agnsed\")\n",
    "xspec.AllModels.lmod(\"agnmodel\", \"/home/raad/PhD/Data/Work_Dir/agnsed\")\n",
    "os.chdir(\"/home/raad/PhD/Dropbox/Code/AGN_togithub\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have some physical constants in cgs units."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 29979245800.\n",
    "M_sol =  1.989e33\n",
    "G = 6.6743e-8\n",
    "m_p = 1.6726219 * 10**-24\n",
    "sig_T = 6.6524 * 10**-25\n",
    "k_B = 1.38064852 * 10**-16\n",
    "keV = 1.60218e-12 * 10**3.\n",
    "sig_SB = 5.6704 * 10**-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we have the parameters of the physical system derived from prior xspec fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_bh_M_sol = 4. * 10**7\n",
    "D = 19\n",
    "logmdot = -1.86505\n",
    "astar = 0.\n",
    "cosi = 0.6\n",
    "redshift = 0.0033\n",
    "\n",
    "logrout=5.\n",
    "r_o=10**logrout\n",
    "r_DS = 390.\n",
    "r_SH = 90.1314\n",
    "r_i = 6.\n",
    "f_irr = 1.\n",
    "hx = 10.\n",
    "kT_hot = 100.\n",
    "kT_warm = 0.17\n",
    "Gamma_hot = 1.793\n",
    "Gamma_warm = 2.7\n",
    "\n",
    "incl = np.arccos(cosi)\n",
    "\n",
    "M_bh = M_bh_M_sol * M_sol\n",
    "R_g = G*M_bh /c**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can boot up xspec within python, and set up our agnsed model and environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "os.chdir(\"xspec_placeholder_data\")\n",
    "\n",
    "s = xspec.Spectrum(\"source_c20.pi\")\n",
    "m = xspec.Model(\"agnsed\")\n",
    "xspec.AllData.dummyrsp(1e-5,1e3,10000)\n",
    "\n",
    "\n",
    "xspec.Xset.abund = \"grsa\"\n",
    "xspec.Xset.cosmo = \"70 0 0.73\"\n",
    "xspec.Xset.xsect = \"bcmc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can individually model the disc and soft and hard Compton components, and save their fluxes over the energy range (edat) in arrays disc_raw_agnsed_energy, soft_raw_agnsed_energy and hard_raw_agnsed_energy.\n",
    "\n",
    "We will also compute the luminosities of these three components for interest, and to use L_hard later in lightcurve modelling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Modelling the disc.\n",
    "\n",
    "m.setPars(M_bh_M_sol, D, logmdot, astar, cosi, kT_hot, kT_warm,\\\n",
    "          Gamma_hot, \"-{},1e-2,-2.7,-2.7,2.7,2.7\".format(Gamma_warm), r_SH, r_DS, logrout, hx, 1., redshift,1)\n",
    "xspec.Plot(\"emo\")\n",
    "edat = np.asarray(xspec.Plot.x())\n",
    "F_disc_raw = np.asarray(xspec.Plot.model())\n",
    "F_disc_raw = np.nan_to_num(F_disc_raw)\n",
    "disc_raw_agnsed_energy = np.trapz(F_disc_raw, edat)\n",
    "xspec.AllModels.calcLumin(\"4e-5 1000. 3.3e-03\")\n",
    "L_disc =s.lumin[0]*1.0e44 # erg s^-1\n",
    "\n",
    "\n",
    "#Modelling the soft Compton.\n",
    "m.setPars(M_bh_M_sol, D, logmdot, astar, cosi, kT_hot, \"-{},,-5.,-5.,100.,100.\".format(kT_warm),\\\n",
    "          Gamma_hot, Gamma_warm, r_SH, r_DS, logrout, hx, 1., redshift,1)\n",
    "xspec.Plot.device = \"null\"\n",
    "xspec.Plot(\"emo\")\n",
    "F_soft_raw = np.asarray(xspec.Plot.model())\n",
    "F_soft_raw = np.nan_to_num(F_soft_raw)\n",
    "soft_raw_agnsed_energy = np.trapz(F_soft_raw, edat)\n",
    "xspec.AllModels.calcLumin(\"4e-5 1000. 3.3e-03\")\n",
    "L_soft =s.lumin[0]*1.0e44 # erg s^-1\n",
    "\n",
    "\n",
    "#Modelling the hard Compton.\n",
    "m.setPars(M_bh_M_sol, D, logmdot, astar, cosi, \"-{},,-100.,-100.,100.,100.\".format(kT_hot), kT_warm,\\\n",
    "          Gamma_hot, Gamma_warm, r_SH, r_DS, logrout, hx, 1., redshift,1)\n",
    "xspec.Plot(\"emo\")\n",
    "F_hard_raw = np.asarray(xspec.Plot.model())\n",
    "F_hard_raw = np.nan_to_num(F_hard_raw)\n",
    "hard_raw_agnsed_energy = np.trapz(F_hard_raw, edat)\n",
    "xspec.AllModels.calcLumin(\"4e-5 1000. 3.3e-03\")\n",
    "L_hard = s.lumin[0]*1.0e44 # erg s^-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's plot what we've modelled to check how our spectrum looks (and that it matches with our original xspec fit!)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax1 = plt.subplots()\n",
    "ax1.plot(edat, edat*F_disc_raw, c = 'red')\n",
    "ax1.plot(edat, edat*F_soft_raw, c = 'green')\n",
    "ax1.plot(edat, edat*F_hard_raw, c = 'cyan')\n",
    "ax1.axvspan(12.398/2950., 12.398/2250, color = 'g', alpha =0.5)\n",
    "ax1.axvspan(15.5, 150, color = 'b', alpha =0.5)\n",
    "ax1.set_xscale('log')\n",
    "ax1.set_yscale('log')\n",
    "ax1.set_xlabel('$Energy$ $(keV)$')\n",
    "ax1.set_ylabel('$keV^2$ $(Photons$ $cm^{-2}$ $s^{-1}$ $kev^{-1})$')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the overall spectral components are taken care of, we can define some functions describing the radial range we will model on the disc/warm Compton, the temperature due to gravitational dissipation, the heating due to hard X-ray illumination, and the effective temperare on the disc from exernal heating+gravity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_r = 10 # We will model 10 annuli in the soft zone and 10 annuli in the thin disc.\n",
    "\n",
    "def r_bounds(r_o, r_i, N_r):\n",
    "    return np.logspace( log10(r_o), log10(r_i), N_r + 1 )\n",
    "\n",
    "def M_dot(logmdot):\n",
    "    L_Ledd = 10**logmdot\n",
    "    Ledd = 4*pi*G*M_bh*m_p*c/sig_T\n",
    "    L = L_Ledd * Ledd\n",
    "    Mdot=  L / (0.0572 * c**2)\n",
    "    return Mdot \n",
    "\n",
    "def T_grav_F_grav(r, dr):\n",
    "    Mdot = M_dot(logmdot)\n",
    "    temp = ((G*M_bh*Mdot/(8*pi*sig_SB)) * (r*R_g)**-3. * 3 )**(1./4.)\n",
    "    return k_B * temp / keV, sig_SB*temp**4\n",
    "\n",
    "def F_rep(r, L_cor=L_hard):\n",
    "    n = pi/2. - np.arctan2(hx, r)\n",
    "    l = np.sqrt(r**2 + hx**2)\n",
    "    return f_irr * L_cor * np.cos(n) / (4*pi*(l*R_g)**2)\n",
    "\n",
    "def T_eff(r, dr, L_cor=L_hard):\n",
    "    T_g, F_g = T_grav_F_grav(r, dr)\n",
    "    F_r = F_rep(r, L_cor)    \n",
    "    T_out = T_g * ((F_r+F_g)/F_g)**0.25\n",
    "    return T_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we model the energy spectrum from every annulus in the thermal disc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We define the radial range and annular thicknesses on our disc.\n",
    "r_bins_disc = r_bounds(r_o, r_DS, N_r)\n",
    "rs_disc = np.asarray([(r_bins_disc[i+1]+r_bins_disc[i])/2 for i in range(len(r_bins_disc)-1)])\n",
    "drs_disc = [(r_bins_disc[i] -r_bins_disc[i+1]) for i in range(len(r_bins_disc)-1)]\n",
    "\n",
    "# Now we compute the time-averaged gravitational heating temperature, the heating temperature, \n",
    "# the gravitational dissipation flux, the X-ray heating flux and the overall temperature for every annulus\n",
    "# on the disc.\n",
    "T_gravs_disc = np.zeros(N_r)\n",
    "F_gravs_disc = np.zeros(N_r)\n",
    "F_reps0_disc = np.zeros(N_r)\n",
    "T_effs0_disc = np.zeros(N_r)\n",
    "repfracs_disc = np.zeros(N_r)\n",
    "\n",
    "for i in range(N_r):\n",
    "    T_gravs_disc[i] = T_grav_F_grav(rs_disc[i],drs_disc[i])[0]    \n",
    "    F_gravs_disc[i] = T_grav_F_grav(rs_disc[i],drs_disc[i])[1]\n",
    "    F_reps0_disc[i] = F_rep(rs_disc[i])\n",
    "    repfracs_disc[i] = F_reps0_disc[i] / F_gravs_disc[i]\n",
    "    T_effs0_disc[i] = T_eff(rs_disc[i],drs_disc[i])\n",
    "\n",
    "# We now normalize the spectral shape of our annular thermal spectra so that the energy in their sum equals the\n",
    "# energy in the AGNSED thermal component.\n",
    "\n",
    "def discnorms():\n",
    "    m = xspec.Model(\"bbody\")\n",
    "    m.setPars(\"0.2,-1,1e-8,1e-8,0.2,0.2\", \"100.\")\n",
    "    disc_fluxes = np.zeros((N_r, len(edat)))\n",
    "    total_disc_r = np.zeros(N_r)\n",
    "    for i in range(N_r):\n",
    "        r = rs_disc[i]\n",
    "        dr = drs_disc[i]\n",
    "        eps = r**-3. * 3 * (1- np.sqrt(r_DS/r)) * r * dr\n",
    "        T_effr = T_effs0_disc[i]            \n",
    "        m.setPars({1:T_effr})\n",
    "        xspec.Plot(\"emo\")\n",
    "        disc_fluxes[i] = np.nan_to_num(np.asarray(xspec.Plot.model())) * eps\n",
    "        total_disc_r[i] = np.trapz(disc_fluxes[i], edat)\n",
    "    disc_raw_comptt_energy= np.sum(total_disc_r)\n",
    "    norm = disc_raw_agnsed_energy / disc_raw_comptt_energy\n",
    "    return norm\n",
    "\n",
    "# discnorm is only computed once, andis what we will use in the following modelling to ensure that the fluxes\n",
    "# from our annuli are consistent with the AGNSED-fit spectrum.\n",
    "discnorm = discnorms()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we will plot all of our disc annuli to see how they contribute to the UVW1 band."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax2 = plt.subplots()\n",
    "\n",
    "m = xspec.Model(\"bbody\")\n",
    "m.setPars(\"0.2,-1,1e-8,1e-8,0.2,0.2\", \"100.\")\n",
    "disc_fluxes = np.zeros((N_r, len(edat)))\n",
    "total_disc_r = np.zeros(N_r)\n",
    "for i in range(N_r):\n",
    "    r = rs_disc[i]\n",
    "    dr = drs_disc[i]\n",
    "    eps = r**-3. * 3 * (1- np.sqrt(r_DS/r)) * r * dr\n",
    "    T_effr = T_effs0_disc[i]            \n",
    "    m.setPars({1:T_effr})\n",
    "    xspec.Plot(\"emo\")\n",
    "    disc_fluxes[i] = np.nan_to_num(np.asarray(xspec.Plot.model())) * eps\n",
    "    ax2.plot(edat, discnorm*edat*disc_fluxes[i], linestyle = '--')\n",
    "\n",
    "ax2.plot(edat, discnorm*edat*np.sum(disc_fluxes,axis=0), c = 'darkred')\n",
    "ax2.axvspan(12.398/2950., 12.398/2250, color = 'g', alpha =0.5)\n",
    "ax2.axvspan(15.5, 150, color = 'b', alpha =0.5)\n",
    "ax2.set_xscale('log')\n",
    "ax2.set_yscale('log')\n",
    "ax2.set_xlabel('$Energy$ $(keV)$')\n",
    "ax2.set_ylabel('$keV^2$ $(Photons$ $cm^{-2}$ $s^{-1}$ $kev^{-1})$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now repeat the above procedure for the warm Compton zone, and plot our resultant annular spectra."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_bins_warm = r_bounds(r_DS, r_SH, N_r)\n",
    "rs_warm = np.asarray([(r_bins_warm[i+1]+r_bins_warm[i])/2 for i in range(len(r_bins_warm)-1)])\n",
    "drs_warm = [(r_bins_warm[i] -r_bins_warm[i+1]) for i in range(len(r_bins_warm)-1)]\n",
    "\n",
    "T_gravs_warm = np.zeros(N_r)\n",
    "T_effs0_warm = np.zeros(N_r)\n",
    "F_gravs_warm = np.zeros(N_r)\n",
    "F_reps0_warm = np.zeros(N_r)\n",
    "repfracs_warm = np.zeros(N_r)\n",
    "for i in range(N_r):\n",
    "    T_gravs_warm[i] = T_grav_F_grav(rs_warm[i],drs_warm[i])[0]    \n",
    "    F_gravs_warm[i] = T_grav_F_grav(rs_warm[i],drs_warm[i])[1]\n",
    "    F_reps0_warm[i] = F_rep(rs_warm[i])\n",
    "    repfracs_warm[i] = F_reps0_warm[i] / F_gravs_warm[i]\n",
    "    T_effs0_warm[i] = T_eff(rs_warm[i],drs_warm[i])\n",
    "\n",
    "def compnorms():\n",
    "    m = xspec.Model(\"nthcomp\")\n",
    "    m.setPars(Gamma_warm,\"{},,0.,0.,100.,100.,\".format(kT_warm),\"0.00056,,0.,0.,100.,100.\",0.,redshift,\"1.\")\n",
    "    soft_fluxes = np.zeros((N_r, len(edat)))\n",
    "    total_comptt_r = np.zeros(N_r)\n",
    "    for i in range(N_r):\n",
    "        r = rs_warm[i]\n",
    "        dr = drs_warm[i]\n",
    "        eps = r**-3. * 3 * (1- np.sqrt(r_SH/r)) * r * dr\n",
    "        T_effr = T_effs0_warm[i]\n",
    "        m.setPars({3:T_effr})\n",
    "        xspec.Plot(\"emo\")\n",
    "        soft_fluxes[i] = np.nan_to_num(np.asarray(xspec.Plot.model())) * eps\n",
    "        total_comptt_r[i] = np.trapz(soft_fluxes[i], edat)\n",
    "    soft_raw_comptt_energy= np.sum(total_comptt_r)\n",
    "    norm = soft_raw_agnsed_energy / soft_raw_comptt_energy\n",
    "\n",
    "    return norm\n",
    "\n",
    "compnorm = compnorms()\n",
    "\n",
    "\n",
    "\n",
    "f, ax3 = plt.subplots()\n",
    "\n",
    "m = xspec.Model(\"nthcomp\")\n",
    "m.setPars(Gamma_warm,\"{},,0.,0.,100.,100.,\".format(kT_warm),\"0.00056,,0.,0.,100.,100.\",0.,redshift,\"1.\")\n",
    "soft_fluxes = np.zeros((N_r, len(edat)))\n",
    "total_comptt_r = np.zeros(N_r)\n",
    "for i in range(N_r):\n",
    "    r = rs_warm[i]\n",
    "    dr = drs_warm[i]\n",
    "    eps = r**-3. * 3 * (1- np.sqrt(r_SH/r)) * r * dr\n",
    "    T_effr = T_effs0_warm[i]\n",
    "    m.setPars({3:T_effr})\n",
    "    xspec.Plot(\"emo\")\n",
    "    soft_fluxes[i] = np.nan_to_num(np.asarray(xspec.Plot.model())) * eps\n",
    "    ax3.plot(edat, compnorm*edat*soft_fluxes[i], linestyle = '--')\n",
    "    total_comptt_r[i] = np.trapz(soft_fluxes[i], edat)\n",
    "ax3.plot(edat, compnorm*edat*np.sum(soft_fluxes,axis=0), c = 'darkgreen')\n",
    "\n",
    "ax3.axvspan(12.398/2950., 12.398/2250, color = 'g', alpha =0.5)\n",
    "ax3.axvspan(15.5, 150, color = 'b', alpha =0.5)\n",
    "ax3.set_xscale('log')\n",
    "ax3.set_yscale('log')\n",
    "ax3.set_xlabel('$Energy$ $(keV)$')\n",
    "ax3.set_ylabel('$keV^2$ $(Photons$ $cm^{-2}$ $s^{-1}$ $kev^{-1})$')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now deal with the timing-exclusive aspects of our model.\n",
    "\n",
    "First we define the transfer function for an annulus with inner edge r_inner and outer edge r_outer, according to the procedure of Welsh & Horne (1991)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def point_illum_transferfn(r_outer, r_inner):\n",
    "    N_disc = 500\n",
    "    N_phi = 500\n",
    "    dphi = 2*pi / N_phi\n",
    "    taus = np.arange(0, 500, dt_dat)\n",
    "    \n",
    "    r_bins = np.linspace( r_outer, r_inner, N_disc + 1 )\n",
    "    rs = np.asarray([(r_bins[i+1]+r_bins[i])/2 for i in range(len(r_bins)-1)])\n",
    "    drs = [(r_bins[i] -r_bins[i+1]) for i in range(len(r_bins)-1)]\n",
    "    \n",
    "    tf = np.zeros(len(taus))\n",
    "    for i in range(N_disc):\n",
    "        for j in range(N_phi):\n",
    "            t = rs[i] * R_g / (c*86400) * (1.0 - np.sin(incl)*np.cos(-pi/2. + dphi*j))\n",
    "            tindex = int(t/dt_dat)+1\n",
    "            f_r = drs[i]/(r_outer - r_inner)\n",
    "            f_phi = dphi/(2.*pi)\n",
    "            tf[tindex] += f_r*f_phi\n",
    "    return taus, tf\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can define the time-delayed hard X-ray time series as seen by each disc and warm Compton annulus."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lagged_array(N_r, rs, drs):\n",
    "    lagged_driving = np.zeros((N_r, len(comparison_times_rebn)))\n",
    "    for i in range(N_r):\n",
    "        r, dr = rs[i], drs[i]\n",
    "        len_T = len(comparison_times)\n",
    "        outcurve = np.zeros(len_T)\n",
    "        tf = point_illum_transferfn(r+dr/2, r-dr/2)[1]\n",
    "        for j in range(len_T):\n",
    "            for k in range(len_T):\n",
    "                if k-j >= 0:\n",
    "                    outcurve[k] += tf[j]*flux_BAT_int[k-j]   \n",
    "        digitized = np.digitize(comparison_times, bins)\n",
    "        outcurve_rebn = np.asarray([outcurve[digitized == p].mean() for p in range(1, len(bins))])\n",
    "        lagged_driving[i] = outcurve_rebn\n",
    "    return lagged_driving\n",
    "\n",
    "lagged_driving_disc = lagged_array(N_r, rs_disc, drs_disc)\n",
    "lagged_driving_disc_aves = np.mean(lagged_driving_disc, axis = 1)\n",
    "\n",
    "lagged_driving_warm = lagged_array(N_r, rs_warm, drs_warm)\n",
    "lagged_driving_warm_aves = np.mean(lagged_driving_warm, axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "At last we can now run the model to recover the predicted UVW1 lightcurve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_UVW1_min = min(np.argwhere(edat>(E_UVW1-dE_UVW1)))[0]\n",
    "i_UVW1_max = min(np.argwhere(edat>(E_UVW1+dE_UVW1)))[0]\n",
    "\n",
    "def UVW1curve():\n",
    "    soft_fluxes = np.zeros((N_r, len(edat)))\n",
    "    driving = flux_BAT_rebn / np.average(flux_BAT_rebn)\n",
    "    xspec.AllData.dummyrsp(1e-5,1e3,10000)\n",
    "    \n",
    "    m = xspec.Model(\"nthcomp\")\n",
    "    m.setPars(Gamma_warm,\"{},,0.,0.,100.,100.,\".format(kT_warm),\"0.00056,,0.,0.,100.,100.\",0.,redshift,\"1.\")\n",
    "    xspec.Plot.device = \"null\"\n",
    "\n",
    "    emissivities = np.zeros(N_r)\n",
    "    lightcurve = np.zeros(len(comparison_times_rebn))\n",
    "    for i in range(N_r):\n",
    "        r = rs_warm[i]\n",
    "        dr = drs_warm[i]\n",
    "        emissivities[i] = r**-3. * 3 * (1- np.sqrt(r_SH/r)) * r * dr\n",
    "        \n",
    "    for j in range(len(comparison_times_rebn)):\n",
    "        \n",
    "        lightcurve[j] += np.trapz(driving[j] * F_hard_raw[i_UVW1_min:i_UVW1_max+1], edat[i_UVW1_min:i_UVW1_max+1])\n",
    "        \n",
    "        for i in range(N_r):\n",
    "            fluctuation = lagged_driving_warm[i,j] / lagged_driving_warm_aves[i]\n",
    "            L_cor_t = L_hard * fluctuation            \n",
    "            r, dr = rs_warm[i], drs_warm[i]\n",
    "            T_r = T_eff(r, dr, L_cor_t)\n",
    "            m.setPars({3:T_r})\n",
    "            xspec.Plot(\"emo\")\n",
    "            soft_fluxes[i] = np.nan_to_num(np.asarray(xspec.Plot.model())) * compnorm * emissivities[i] * (1.+repfracs_warm[i]*(fluctuation-1))\n",
    "            lightcurve[j] += np.trapz(soft_fluxes[i][i_UVW1_min:i_UVW1_max+1], edat[i_UVW1_min:i_UVW1_max+1])\n",
    "    \n",
    "    \n",
    "    # Uncomment the block below to include reprocessing on the thermal disc which we note has only a negligible\n",
    "    # impact on the lightcurve due to the lack of thermal photons in the UVW1 band.\n",
    "    '''\n",
    "    disc_fluxes = np.zeros((N_r, len(edat)))\n",
    "\n",
    "    m = xspec.Model(\"bbody\")\n",
    "    m.setPars(\"0.2,-1,1e-8,1e-8,0.2,0.2\", \"100.\")\n",
    "    xspec.Plot.device = \"null\"\n",
    "\n",
    "    emissivities = np.zeros(N_r)\n",
    "    for i in range(N_r):\n",
    "        r = rs_disc[i]\n",
    "        dr = drs_disc[i]\n",
    "        emissivities[i] = r**-3. * 3 * (1- np.sqrt(r_DS/r)) * r * dr\n",
    "\n",
    "    for j in range(len(comparison_times_rebn)):\n",
    "        \n",
    "        for i in range(N_r):\n",
    "            fluctuation = lagged_driving_disc[i,j] / lagged_driving_disc_aves[i]\n",
    "            L_cor_t = L_hard * fluctuation \n",
    "            r, dr = rs_disc[i], drs_disc[i]\n",
    "            T_r = T_eff(r, dr, L_cor_t)\n",
    "            m.setPars({1:T_r})\n",
    "            xspec.Plot(\"emo\")\n",
    "            disc_fluxes[i] = np.nan_to_num(np.asarray(xspec.Plot.model())) * discnorm * emissivities[i] * (1.+repfracs_disc[i]*(fluctuation-1))\n",
    "            lightcurve[j] += np.trapz(disc_fluxes[i][i_UVW1_min:i_UVW1_max+1], edat[i_UVW1_min:i_UVW1_max+1])\n",
    "    '''\n",
    "    \n",
    "    return lightcurve\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plotting the lightcurve below, we indeed find that it is a poor fit to the data, ruling out optically thick material at r<400 Rg!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "UV_lc = UVW1curve()\n",
    "\n",
    "f, (ax1, ax2) = plt.subplots(2, sharex=True)\n",
    "ax1.errorbar(comparison_times_rebn, flux_BAT_rebn/np.average(flux_BAT_rebn), flux_err_BAT_rebn/np.average(flux_BAT_rebn), label = 'BAT', c= 'blue')\n",
    "ax2.plot(comparison_times_rebn, UV_lc/np.average(UV_lc), label = 'UVW1 predicted', c = 'r')\n",
    "ax2.errorbar(comparison_times_rebn, flux_UVW1_rebn/np.average(flux_UVW1_rebn), flux_err_UVW1_rebn/np.average(flux_UVW1_rebn), label = 'UVW1 data', c= 'blue')\n",
    "ax2.set_xlabel('MJD')\n",
    "ax2.set_ylabel('Normalised Flux')\n",
    "ax1.set_ylabel('Normalised Flux')\n",
    "ax1.tick_params(axis = 'both', bottom='on', top='on', left='on', right='on', direction= 'in')\n",
    "ax2.tick_params(axis = 'both', bottom='on', top='on', left='on', right='on', direction= 'in')\n",
    "\n",
    "f, ax = plt.subplots()\n",
    "CCF_dat = CCF_corrected(flux_UVW1_rebn[startcut:], flux_BAT_rebn[startcut:], dt_rebn, flux_err_UVW1_rebn[startcut:], flux_err_BAT_rebn[startcut:])\n",
    "CCF_mod = CCF_corrected(UV_lc[startcut:], flux_BAT_rebn[startcut:], dt_rebn,  flux_err_UVW1_rebn[startcut:]/np.average(flux_UVW1_rebn[startcut:]) * np.average(UV_lc[startcut:]), h_err = flux_err_BAT_rebn[startcut:], mode=  'nocorr')\n",
    "ax.tick_params(axis = 'both', bottom='on', top='on', left='on', right='on', direction= 'in')\n",
    "ax.plot(taus, CCF_dat, c = 'b')\n",
    "ax.plot(taus, CCF_mod, c = 'r')\n",
    "ax.set_title('')\n",
    "ax.set_xlabel(r'$\\tau$ (days)')\n",
    "ax.set_ylabel('Normalised CCF')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
